{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Démo de S9",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttVB1SCenG4y"
      },
      "source": [
        "#Démo pour l'embarquement d'un réseau de neuronnes sur Maixduino\n",
        "\n",
        "Ce fichier est un fichier colab, qui va nous permettre de combiner entre des texts et des lignes de code. Colab est généralement utilisé pour des projets d'intelligence artificielle, en nous donnant la possibilité de travailler avec un GPU et une mémoire RAM importante, la possibilité de partage.\n",
        "\n",
        "Colab nous permet aussi d'utiliser plusieurs bibliothèques de python, pour construire des models de Deep learning, des courbes, des analyses, ou des simples transformations de données. La ligne suivante va nous permettre de voir une des fonctionnalités que colab nous permet de faire. \n",
        "\n",
        "Le bloc de code suivant est un script Python qui utilise deux bibliothèques, numpy une bibliothèque de manipulation de matrices et tableaux multidimmensionnels,et matplotlib pour générer des courbes ou  afficher des images, ce script va générer une courbe random et la dessiner en utilisant la bibliothèque matplotlib.\n",
        "\n",
        "Vous n'avez qu'à démarer la ligne suivante pour voir ce fontionnement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGMK8wLqm7ei"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "ys = 200 + np.random.randn(100)\n",
        "x = [x for x in range(len(ys))]\n",
        "\n",
        "plt.plot(x, ys, '-')\n",
        "plt.fill_between(x, ys, 195, where=(ys > 195), facecolor='g', alpha=0.6)\n",
        "\n",
        "plt.title(\"Sample Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93rNhJHHwYQt"
      },
      "source": [
        "### Commandes shell\n",
        "\n",
        "Parmi les fonctionnalités que colab nous offre aussi, la possibilité de manipuler l'environnement d'exécution, comme la création d'un fichier ou un dossier en utilisant des commandes shell, ou installer des nouvelles librairies.\n",
        "Les commandes shell doivent être précédées d'un point d'exclamation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GiDcE16yeMD"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVaBI5QKyhnW"
      },
      "source": [
        "!mkdir embedded\n",
        "!touch /content/embedded/main.c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol2TD2EPyjVh"
      },
      "source": [
        "Vous pouvez vérifier la création de ce dossier, ce dossier contient un fichier main.c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG9o3b1O01iZ"
      },
      "source": [
        "#Machine learning\n",
        "\n",
        "le Machine-learning ou l'apprentissage automatique sont des techniques qui permettent à la machine d'apprendre à faire des prédiction avec l'entrainnement. le codage normal, est de donner à la machine des régles claires à respecter et lui donner après une entrée pour vous donner la sortie, mais le machine-learning, qui fait partie de l'intelligence artificielle, utilise une autre technique, c'est de donner à la machine des entrées et leurs sorties et laisser la machine deviner les régles pour obtenir la même sortie, au fur et à mesure la machine commence à donner des prédictions très précises.\n",
        "\n",
        "Le deep-learning ou l'apprentissage profond est une des branches du machine-learning qui nous permet de créer des réseaux de neuronnes afin de prédire des réponses complexes.\n",
        "\n",
        "Nous allons créer un réseau de neuronnes simple pour prédire la fonction f(x)=2x+0.1, pour cela nous allons pas décrir la fonction, mais nous allons donner au réseau des exemples d'entrées avec leurs sorties.\n",
        "\n",
        "Les réseaux de neuronnes donnent des meilleurs résultats, si toutes les variables sont entre 1 et -1, alors je vais travailler avec des -1<x<1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSr9P7oe4vkI"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "X = np.array([0,0.1,0.2,-0.4,-0.7,0.134,0.353,0.356, 0.-145,-0.4])\n",
        "Y = np.empty(shape=0, dtype=float)\n",
        "\n",
        "# Calculate Y-Values\n",
        "for x in X:\n",
        "    Y = np.append(Y, float(2*x +0.1))\n",
        "\n",
        "\n",
        "# model architecture\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(1, input_shape=(1,)))\n",
        "model.add(keras.layers.Dense(8))\n",
        "model.add(keras.layers.Activation(\"linear\"))\n",
        "model.add(keras.layers.Dense(4))\n",
        "model.add(keras.layers.Activation(\"linear\"))\n",
        "model.add(keras.layers.Dense(1))\n",
        "model.add(keras.layers.Activation(\"linear\"))\n",
        "# compile model\n",
        "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# train model\n",
        "model.fit(X, Y, epochs=250, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdS2JIP6F13F"
      },
      "source": [
        "Regardez les predictions suivantes et les comparer avec les résultats corrects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft5jOF3v5hrx"
      },
      "source": [
        "y_pred = model.predict([0,0.1, 0.3, 0.34, 0.12])\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSTMiNKDqNCp"
      },
      "source": [
        "#Préparation de la base de données\n",
        "\n",
        "Avant de commencer, soyez sûr que vous utilisez un GPU\n",
        "\n",
        "\n",
        "Exécution -> Modifier le type d'exécution -> GPU -> enregistrer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xMp47DmzliE"
      },
      "source": [
        "Maintenant, après une petite introduction de ce que nous désignons par le machine learning, nous allons entrer dans le vif du sujet, d'ailleurs le sujet est l'embarquement d'un réseau de neuronnes sur la carte MaixDuino, nous commençons par la préparation de la data, sans data le machine learning fonctionnera jamais.\n",
        "\n",
        "Pour cela, nous allons utiliser une base de donnée qui s'appelle CelebA, et qui contient 202k images, vous pouvez la trouver sur le site web http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html , vous pouvez télécharger la base de données, et la charger sur colab. Pour notre cas, nous allons utiliser un quart de cette base, car travailler avec toute la base est impossible, vu les quotas imposés par Google.\n",
        "\n",
        "La base de données est déjà prête, vous n'avez qu'à récupérer deux fichier .zip et les décompresser, chaque dossier contient deux dossier \"train\" et \"val\", train contient 19999 images ou 19999 fichiers xml, et val contient 2000 images ou 2000 fichiers xml, chaque fichier xml contient les coordonnées des cadres des visages, vous pouvez ouvrir un fichier xml, et analyser les informations qu'il contient.\n",
        "\n",
        "Téléchargez les deux bases de données qui seront fournies, et décompressez ces bases avec les deux lignes de code suivantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2_dcMTZHAT7"
      },
      "source": [
        "!unzip /content/celebaForModel-20210111T145135Z-001.zip\n",
        "!unzip /content/celebaForModelXML-20210111T150438Z-001.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_xRO1chPgY0"
      },
      "source": [
        "Vous pouvez remarquer que y a deux dossier qui viennent de s'ajouter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKEZ7HZeRius"
      },
      "source": [
        "#aXeleRate\n",
        "\n",
        "Axelerate est un projet open source fait par un ingénieur russe qui s'appelle Dmitry MASLOV, qui travaille dans le domaine de l'intelligence artificielle embarquée, M.MASLOV a participé à la réalisation de ce projet.\n",
        "\n",
        "La carte Maixduino n'accepte que des fichier kmodels, car le kpu a une configuration particulière, pour créer un model kmodel nous devons créer un modèle h5 avec Tensorflow, après nous le transformons en fichier tflite, qui utilise des int de 16-bits à la place de 32-bits ce qui réduit la taille du model par 2, au moins. Ensuite le fichier tflite sera transformé en fichier kmodel. Tout cela sera fait par aXeleRate.\n",
        "\n",
        "Axelerate est un outil pour créer des fichier kmodel, elle fait toutes les transformations nécessaires, et il suffit de préciser ce que nous voulons faire à l'aide d'un fichier de configuration ou un dictionnaire de configuration.\n",
        "\n",
        "Nous commonçons par ajouter la bibiliothèque aXeleRate, nous ajoutons aussi une ancienne version de la bibliothèque imgaug, pour éviter des conflits de versions.\n",
        "\n",
        "imgaug est une bibiothèque pour l'augmentation de data, si par exemple vous avez une image d'une fleur vous pouvez avoir 5 images de cette fleur en appliquant une transformation miroir, tourner l'image de 20° ainsi de suite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRqz_Kf8R55r"
      },
      "source": [
        "!pip uninstall -y imgaug && pip uninstall -y albumentations && pip install imgaug==0.4\n",
        "!git clone https://github.com/AIWintermuteAI/aXeleRate.git\n",
        "import sys\n",
        "sys.path.append('/content/aXeleRate')\n",
        "from axelerate import setup_training, setup_inference"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wFpNDblZGAw"
      },
      "source": [
        "#Visualisation des images\n",
        "Nous pouvons utiliser la fonction visualize_detection_dataset pour visualiser notre base de données, et visualiser quelques exemple de l'augmentation de data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGhcMa04Zes5"
      },
      "source": [
        "from axelerate.networks.common_utils.augment import visualize_detection_dataset\n",
        "\n",
        "visualize_detection_dataset(img_folder='/content/celebaForModel/train', ann_folder='/content/celebaForModelXML/train', num_imgs=10, img_size=320, augment=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHIjjcMBa7Ox"
      },
      "source": [
        "#File configuration\n",
        "\n",
        "Pour notre cas, c'est plus simple d'utiliser un dictionnaire à la place d'un fichier de configuration d'aXeleRate, mais le contenu est le même, dans ce fichier de configuration nous allons préciser à aXeleRate comment elle doit construire le model, comment elle doit l'entrainer et où elle doit le stocker ou l'enregistrer.\n",
        "\n",
        "Pour bien comprendre ce qui va se passer après, nous expliquons les keys du dictionnaire:\n",
        "\n",
        "- type c'est le type de model que nous voulons faire, Detector, Segnet ou Classifier, pour notre cas c'est un detecteur de visage alors nous allons choisir Detector.\n",
        "-architecture, c'est l'architecture du model, y'en a plusieurs architecture que les experts ont démontré leur efficacité. Les architectures que aXeleRate soutienne sont: Full Yolo - Tiny Yolo - MobileNet1_0 - MobileNet7_5 - MobileNet5_0 - MobileNet2_5 - SqueezeNet - VGG16 - ResNet50, avec notre carte nous ne pouvons pas utiliser des architectures très développées, notre model ne doit pas dépassé la taille 2MB, alors nous devons choisir entre Tiny Yolo, MobileNet(jusqu'à alpha 0.75) et SqueezeNet.\n",
        "-input_size, c'est la taille des entrées, y a deux possibilités 224x224(224) ou 240x320(320), avec les models classiques, l'entrainement avec des images carrées est plus efficace que l'entrainement avec des images qui ne sont pas carrées.\n",
        "-anchors, c'est une spécialité de Yolo, pour faire la différence entre les différents cadres(https://towardsdatascience.com/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9)\n",
        "-labels, c'est les labels que notre base de données contient, vous pouvez lire un des fichier xml, que la base de données contient, pour mieux comprendre.\n",
        "-les 4 scales, sont pour fixer à quel point le model doit pénaliser des fausses prédictions.\n",
        "-weights:\n",
        "\n",
        "  * full: si nous avons un même model pré-entrainé, nous pouvons utiliser ce model pour l'entrainer de plus\n",
        "  *backend: des weights pré-entrainés sur une autre tâche, mais ils sont simple plus à réentrainer, cela s'appelle le transfert de l'apprentissage.\n",
        "-actual-epoch, combien d'epochs nous aimerions faire entrainer notre model\n",
        "-train_image_folder, le dossier contenant les images d'entrainement\n",
        "-train_annot_folder, le dossier contenant les réponses, les positions de cadres\n",
        "-train_times, combien de fois nous voulons répéter l'entrainement\n",
        "-val_image_folder, le dossier contenant les images de validation\n",
        "-val_annot_folder, le dossier contenant les réponses, les positions de cadres\n",
        "-valid_times, combien de fois nous voulons répéter la validation\n",
        "-batch_size, la taille des batchs d'entrainnement\n",
        "-learning_rate, le coefficient d'entrainement initial\n",
        "-saved_folder, l'endroit où nous voulons enregistrer le model\n",
        "-first_trainable_layer, le premier layer à entrainer(au cas où nous voulons pas entrainer les premiers layers du modèle)\n",
        "-augmentation, l'augmentation de la base des données\n",
        "\n",
        "La majorité de ces données ne sont pas à changer, les seules informations que nous pouvions changer sont les endroits où nous avons la bases de données, l'endroit où nous voulons enregistrer le model résultat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29ts5jOTaMaC"
      },
      "source": [
        "!mkdir kendryteModel\n",
        "\n",
        "config = {\n",
        "        \"model\":{\n",
        "            \"type\":                 \"Detector\",\n",
        "            \"architecture\":         \"MobileNet7_5\",\n",
        "            \"input_size\":           224,\n",
        "            \"anchors\":              [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],\n",
        "            \"labels\":               [\"face\"],\n",
        "            \"coord_scale\" : \t\t1.0,\n",
        "            \"class_scale\" : \t\t1.0,\n",
        "            \"object_scale\" : \t\t5.0,\n",
        "            \"no_object_scale\" : \t1.0\n",
        "        },\n",
        "        \"weights\" : {\n",
        "            \"full\":   \t\t\t\t\"\",\n",
        "            \"backend\":   \t\t    \"imagenet\"\n",
        "        },\n",
        "        \"train\" : {\n",
        "            \"actual_epoch\":         15,\n",
        "            \"train_image_folder\":   \"/content/celebaForModel/train\",\n",
        "            \"train_annot_folder\":   \"/content/celebaForModelXML/train\",\n",
        "            \"train_times\":          1,\n",
        "            \"valid_image_folder\":   \"/content/celebaForModel/val\",\n",
        "            \"valid_annot_folder\":   \"/content/celebaForModelXML/val\",\n",
        "            \"valid_times\":          1,\n",
        "            \"valid_metric\":         \"mAP\",\n",
        "            \"batch_size\":           32,\n",
        "            \"learning_rate\":        1e-4,\n",
        "            \"saved_folder\":   \t\tF\"/content/kendryteModel\",\n",
        "            \"first_trainable_layer\": \"\",\n",
        "            \"augumentation\":\t\t\t\tTrue,\n",
        "            \"is_only_detect\" : \t\tFalse\n",
        "        },\n",
        "        \"converter\" : {\n",
        "            \"type\":   \t\t\t\t[\"k210\",\"tflite\"]\n",
        "        }\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hy8jWtyqGMg"
      },
      "source": [
        "Tensorboard pour effectuer des statistics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnFY3wU5qCkF"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n",
        "!sleep 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20jfABloq6EX"
      },
      "source": [
        "Vérifier que vous utiliser un GPU, et quel GPU vous utiliser\n",
        "\n",
        "Un entrainement sans GPU est extrêmement long"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgbkyF87rSKD"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5ZbtH5yrXV8"
      },
      "source": [
        "Maintenant nous allons commencer l'entrainement de notre model, en utilisant axelerate, cette opération va probabelement prendre énormément du temps, et si vous n'avez pas précisé l'utilisation d'un GPU, vous devez le faire.\n",
        "\n",
        "Lancer le code suivant et regardez les premiers messages pour comprendre encore mieux, quand l'entrainement commence, prenez un café d'une heure 20 min, et vérifier de temps en temps que le model apprend tout le temps, car nous risquons de dépassé les quotas de Colab en terme de nombre d'utilisation du matériel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMMjh-5DrXw1"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "model_path = setup_training(config_dict=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkiaFMfSsiB0"
      },
      "source": [
        "Après la fin de l'entrainement, vérifier bien les performances, et dessiner des courbes de performances si vous voulez, afin de vérifier que notre model fonctionne correctement, nous allons faire des inférences sur les données de la validation.\n",
        "\n",
        "NB: mAP=moyen Average Precision\n",
        "\n",
        "NB: Le modèle ne s'entraine pas sur les images de validation, mais il les utilise pour vérifier s'il apprend bien à prédire des réponses qui n'a jamais vu.\n",
        "\n",
        "alors, démarez la ligne suivante, et regardez si votre model fonctionne bien.\n",
        "\n",
        "Pensez à stopper la ligne après quelques images, car cela ne va jamais arrêter avec 2000 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iczKktO9skcu"
      },
      "source": [
        "%matplotlib inline\n",
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "setup_inference(config, model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ32NMG-PtVh"
      },
      "source": [
        "#Kflash_gui et maixpyide\n",
        "\n",
        "Maintenant, nous avons le fichier kmodel, vous devez ouvrir kendryteModel et ouvrir le dernier dossier, normalement y a qu'un dossier mais si vous avez effectué deux fois l'entrainement, vous devez ourir le dernier dossier; télécharger le fichier kmodel, pour le brûler sur la carte.\n",
        "\n",
        "Télécharger la biblithèque Kflash_gui pour brûler le fichier kmodel sur la carte https://github.com/sipeed/kflash_gui avec git clone, vérifier si le dossier kflash_py n'est pas vide, si c'est le cas, télécharger la bibliothèque kflash_py à partir de ce lien: https://github.com/sipeed/kflash.py/tree/7307f75c962f15392a54620715e22ab5da97b614 .\n",
        "\n",
        "Maintenant, démarez le script avec python3 kflash_gui.py, si cela ne marche pas probablement vous aurez besoin de télécharger quelques bibliothèques Python (avec pip3), comme PyQt5.\n",
        "\n",
        "Quand ce marche bien vous aurez une fenêtre, vous devez préciser quel fichier vous voulez brûler, et c'est clairement le fichier kmodel téléchargé précédemment, au quel endroit vous voulez brûler le script, choisissez 0x300000, précisez que vous travaillez avec Maixduino et à quel port la carte est connectée, généralement ttyUSB0, cliquez ensuite sur Download.\n",
        "\n",
        "quand vous aurez fait cela, téléchargez maixpyIDE, qui est un IDE de sipeed, suivez le tutoriel suivant https://maixpy.sipeed.com/en/get_started/maixpyide.html , démarer le programme avec ./bin/maixpyide, connectez vous à la carte, et lancez le script suivant sur l'IDE(pas sur colab).\n",
        "\n",
        "\n",
        "NB: si vous n'arrivez pas à accéder au port ttyUSB0, penser à changer les permissions, sudo chmod 777 /dev/ttyUSB0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjIC1nGyXbs4"
      },
      "source": [
        "import sensor\n",
        "import image\n",
        "import lcd\n",
        "import KPU as kpu\n",
        "\n",
        "lcd.init()\n",
        "sensor.reset()\n",
        "\n",
        "sensor.set_pixformat(sensor.RGB565)\n",
        "sensor.set_framesize(sensor.QVGA)\n",
        "sensor.set_windowing((224, 224))\n",
        "#sensor.set_vflip(1)\n",
        "sensor.run(1)\n",
        "classes = [\"face\"]\n",
        "task = kpu.load(0x300000)\n",
        "a = kpu.set_outputs(task, 0, 7,7,30)\n",
        "anchor = (1.889, 2.5245, 2.9465, 3.94056, 3.99987, 5.3658, 5.155437, 6.92275, 6.718375, 9.01025)\n",
        "a = kpu.init_yolo2(task, 0.3, 0.3, 5, anchor)\n",
        "while(True):\n",
        "    img = sensor.snapshot()\n",
        "    code = kpu.run_yolo2(task, img)\n",
        "    if code:\n",
        "        for i in code:\n",
        "            a = img.draw_rectangle(i.rect())\n",
        "    a = lcd.display(img)\n",
        "    print(code)\n",
        "a = kpu.deinit(task)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}